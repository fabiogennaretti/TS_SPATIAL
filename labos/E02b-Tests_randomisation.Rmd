---
title: "Tests de randomisation et bootstrap"
output:
  pdf_document:
  html_document:
    self_contained: no
    lib_dir: libs
    theme: spacelab
    toc: yes
    toc_float: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

Ce travail doit être remis avant le **3 février à 17h** sur Moodle.

## Données

Ce laboratoire utilise la base de données Portal, qui contient des données de suivi à long terme de plusieurs espèces de rongeurs sur un site d'étude en Arizona.

> Ernest, M., Brown, J., Valone, T. and White, E.P. (2018) *Portal Project Teaching Database*. [https://figshare.com/articles/Portal_Project_Teaching_Database/1314459](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459).

Le tableau de données [portal_surveys.csv](../donnees/portal_surveys.csv) contient une rangée par individu capturé. Les variables incluent la date (jour, mois, année), le numéro de parcelle, le code d'espèce, le sexe, la longueur de patte arrière et le poids des individus. 

```{r}
surveys <- read.csv("../donnees/portal_surveysB.csv")
str(surveys)
```

Le tableau de données [portal_plots.csv](../donnees/portal_plots.csv) indique le type de traitement appliqué à chaque parcelle. Les traitements visent à exclure différents types de rongeurs: "Control" = aucune clôture, pas d'exclusion; "Rodent Exclosure" = clôture, tous les rongeurs exclus; "Krat Exclosure" = clôture avec porte laissant passer les petits rongeurs, mais pas les rats-kangourous. Ces traitements ont été assignés aléatoirement après délimitation des parcelles.

```{r}
plots <- read.csv("../donnees/portal_plots.csv")
str(plots)
```

## 1. Tests de randomisation

a) Tout d'abord, nous devons préparer les données pour l'analyse:

- Dans le tableau `surveys` ne gardez que les captures de *Néotoma albigula* (NL) où le poid des n'est pas manquant. *Rappel*: La fonction `is.na(x)` vérifie si `x` est une valeur manquante.

<!-- ![Néotoma albigula](https://www.naturepl.com/cache/pcache2/01112522.jpg) -->


```{r include=FALSE, eval=F}
library(tidyverse)

# cheating data
# surveys <- read.csv("../donnees/portal_surveys.csv")
# plots <- read.csv("../donnees/portal_plots.csv")
# 
# dat=surveys %>% inner_join(plots) %>% filter(!is.na(weight)) %>% filter(species_id=="NL") 
# m=lm(weight~year*plot_type,data=dat)
# res=resid(m)
# res2=scale(res^1.3)*sd(res)+mean(res)
# dat$wt= fitted(m)+res2
# surveys=surveys %>% left_join(select(dat,record_id,wt))
# 
# res3=scale(rnorm(nrow(dat),0,sd(res))^1.05)*sd(res)+mean(res)
# dat2=dat %>% select(-plot_type)
# dat2$wt= fitted(m)+res3
# dat2$wt[is.nan(dat2$wt)] <- NA
# hist(res)
# hist(res2)
# hist(res3)
# 
# surveys <- rbind(surveys,filter(dat2,species_id=="NL")) %>% 
#                    arrange(year,month,day) %>% 
#                    mutate(record_id=1:n(),
#                           weight=as.numeric(ifelse(is.na(wt),weight,wt))) %>% select(-wt)
# sum(duplicated(surveys$record_id))
#             
# write.csv(surveys,file = "../donnees/portal_surveysB.csv")



dat= surveys %>% inner_join(plots) %>% filter(!is.na(weight)) %>% 
  filter(plot_type %in% c("Long-term Krat Exclosure","Short-term Krat Exclosure","Control") ) %>%
  filter(species_id=="NL") 


summary(lm(weight~year,data=dat))
confint(lm(weight~year,data=dat))
hist(dat$weight)
qqnorm(dat$weight)
qqline(dat$weight)



m=lm(weight~year*plot_type,data=dat)
summary(m)




summary(lm(weight~year,data=dat))

library(permuco)

lmperm(weight~year*plot_type,data=dat)
hist(dat$weight)
qplot(data = dat,x=year,y=weight)+geom_point()+geom_smooth(method = "lm")
qplot(data = dat,x=year,y=weight,color=plot_type)+geom_point()+geom_smooth(method = "lm")



```

- Finalement, joignez les tableaux `surveys` et `plots` pour connaître les traitements des parcelles liés à chaque observation. Vous pouvez utiliser la fonction `merge` dans R ou la fonction `inner_join`, qui requiet le package *dplyr*. Nommez le tableau résultant `surveys_plots` et n'y conservez que les observations des sites de type "Long-term Krat Exclosure","Short-term Krat Exclosure", et "Control".

Ensuite, visualisez la distribution du poids (`weight`, en grammes) des individus selon l'année.


b) Nous utiliserons un test de randomisation basé sur la régression linéaire pour déterminer si la masse des individus a diminuer avec le temps. Pourquoi penses-tu qu'une approache par permutation soit appropriée ?Pour ce faire, nous écrirons une fonction qui randomise les années, avant d'exécuter la régression. 

c) Créez la fonction décrite en (b), qui effectue une randomisation de `year`, exécute une régression du poids des individus en fonction de l'année, puis retourne la valeur $t$. Déterminez la distribution de cette statistique pour l'hypothèse nulle avec 4999 permutations. Quelle est la valeur $p$ pour la valeur $t$ observée si il n'y a eu aucun changement en masse des individus capturés au court du temps?

d) La différence est-elle significative avec un seuil $\alpha = 0.01$? 


e) Effectuez un test de permutation pour tester si les changements en masses diffèrent selon les traitements (ie. si il y a une intéraction entre year et plot_type).




## 2. Bootstrap

a) Calculez l'intervalle de confiance à 99% pour le changement en masse au court du temps pour chaque traitement.

b) L'intervalle de confiance obtenu en a) est-il cohérent avec le résultat du test en 1.d)? Est-ce que le bootstrap représente bien le processus d'échantillonnage pour ce problème?

c) Utilisez la méthode du bootstrap avec 10 000 réplicats pour calculer la différence de poids des individus entre le début et la fin de l'étude pour les traitements "Long-term Krat Exclosure" et "Control". Effectuez une correction du biais et rapportez la différence corrigée avec son erreur-type.)



