<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Bayesiens hierarchical models 2</title>

<script src="libs/header-attrs-2.20/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">



<h1 class="title toc-ignore">Bayesiens hierarchical models 2</h1>

</div>


<div id="données" class="section level2">
<h2>Données</h2>
<div class="figure">
<img src="../images/GAB4770.jpg" alt="" />
<p class="caption">Svalbard reindeer</p>
</div>
<p>The data are from my post-doc. We will analyze the probability of a
reindeer to have a baby during the summer. In this system, one of the
most important environmental factors is the presence of rain-on-snow
events. These occur when precipitation occurs during the winter. These
freeze and then form a thick layer of ice that blocks access to food
resources.</p>
<p>However, as the Arctic continues to warm, some researchers believe
that the ros will no longer have an effect. When there are sustained
rain events followed by a warm period, the rain causes a release of food
resources and has time to run off before freezing. We will attempt to
explore these changes in the effect of ros.</p>
<pre class="r"><code>library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(cowplot)
library(lubridate)

dat &lt;- read_csv(&quot;../donnees/SvalbardDat.csv&quot;)
dat &lt;- dat %&gt;% mutate(age=year-yrbirth) %&gt;% filter(age&gt;1)

ros &lt;- read_csv(&quot;../donnees/ROS.csv&quot;)</code></pre>
<pre class="r"><code>dat &lt;- dat %&gt;% left_join(ros) %&gt;% 
  mutate(rosNorm = scale(log(ros)),
         ages=scale(age),
         age2=ages^2,
         obsid=1:n(),
         period=cut(year,breaks = seq(1994,2020,by=5)))</code></pre>
<p>We first transform the predictors: - <em>rosNorm</em> is the
logarithm of <em>ros</em>, normalized to have a mean of 0 and a standard
deviation of 1. - we create a variable <em>age2</em> for the quadratic
effect of age - and finally a <em>period</em> variable that separates
the study into 5 periods</p>
<pre class="r"><code>g1 &lt;- dat %&gt;% group_by(age) %&gt;% summarise(mc=mean(calf,na.rm=T),n()) %&gt;% 
  ggplot(aes(age,mc))+geom_point()

g2 &lt;- dat %&gt;% group_by(period,year,rosNorm) %&gt;% summarise(mc=mean(calf,na.rm=T),n()) %&gt;% 
  ggplot(aes(rosNorm,mc,color=period))+geom_point()+geom_smooth(method = lm,se=F)+guides(color=&#39;none&#39;)

plot_grid(g1,g2)</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div
id="bayesian-model-of-the-probability-of-reproduction-according-to-age-and-ros"
class="section level2">
<h2>1. Bayesian model of the probability of reproduction according to
age and ros</h2>
<p>Of course, we will also need to control for the age of the
individuals. The model will therefore be a binomial model with age and
ros as fixed effects. The random effects will consist of the year, the
period and a slope of the ros varying with the period.</p>
<p><em>Notes</em>:</p>
<ul>
<li><p>The model formula in <code>brm</code> follows the same syntax as
<code>lmer</code> for the specification of fixed and random
effects.</p></li>
<li><p>Although it would be possible to add a random country effect on
the <code>age:ros</code> interaction, year, ID, density and several
other control variables. We omit them here to reduce the computational
time of the models.</p></li>
</ul>
<p><strong>A</strong> Choose <em>a priori</em> distributions for the
parameters of the model described above. Here is an example of code
where only the specification of the distributions is missing. The first
four lines define the <em>a priori</em> distributions for the intercept
and coefficients of the three fixed effects, the next three define the
distributions for the standard deviations of the random effects
(<code>class = "sd"</code>), while the last one refers to the standard
deviation of the individual observations
(<code>class = "sigma"</code>).</p>
<pre class="r"><code>library(brms)
my_prior &lt;- c(set_prior(&quot;&quot;, class = &quot;Intercept&quot;),
               set_prior(&quot;&quot;, class = &quot;b&quot;, coef = &quot;ages&quot;),
               set_prior(&quot;&quot;, class = &quot;b&quot;, coef = &quot;age2&quot;),
               set_prior(&quot;&quot;, class = &quot;b&quot;, coef = &quot;rosNorm&quot;),
               set_prior(&quot;&quot;, class = &quot;sd&quot;, coef = &quot;Intercept&quot;, group = &quot;id&quot;),
               set_prior(&quot;&quot;, class = &quot;sd&quot;, coef = &quot;Intercept&quot;, group = &quot;period&quot;),
               set_prior(&quot;&quot;, class = &quot;sd&quot;, coef = &quot;rosNorm&quot;, group = &quot;period&quot;))</code></pre>
<p>It is recommended to choose normal distributions in all cases. For
‘sd’, these distributions will be interpreted as half-normal because it
is implied that these parameters are <span class="math inline">\(\geq
0\)</span>. To choose the mean and standard deviation of each normal
distribution, consider the interpretation of each parameter and in
particular the scales of the predictors <code>ros</code> ,
<code>ages</code> and <code>age2</code>. In bmrs, the family used will
be <code>family=bernoulli("logit")</code>.</p>
<p>As for the standard deviations of the random effects (“sd”), their
distribution <em>a priori</em> can have the same width as that of the
corresponding “b” coefficient.</p>
<pre class="r"><code>library(brms)
my_prior &lt;- c(set_prior(&quot;normal(0,1.5)&quot;, class = &quot;Intercept&quot;),
               set_prior(&quot;normal(.5,.25)&quot;, class = &quot;b&quot;, coef = &quot;ages&quot;),
               set_prior(&quot;normal(-.5,.25)&quot;, class = &quot;b&quot;, coef = &quot;age2&quot;),
               set_prior(&quot;normal(0,.25)&quot;, class = &quot;b&quot;, coef = &quot;rosNorm&quot;),
               # set_prior(&quot;normal(0,.5)&quot;, class = &quot;sd&quot;, coef = &quot;Intercept&quot;, group = &quot;id&quot;),
               set_prior(&quot;normal(0,1)&quot;, class = &quot;sd&quot;, coef = &quot;Intercept&quot;, group = &quot;period&quot;),
               set_prior(&quot;normal(0,.5)&quot;, class = &quot;sd&quot;, coef = &quot;rosNorm&quot;, group = &quot;period&quot;))</code></pre>
<p>the intercept will be centered around 0 with an sd=1.5. This results
in a rather uninformative prior on the probability scale. The priorities
for age are chosen to go from about 0 to a reasonable value. This is
positive for ages and negative for age2. This results in an inverted U
shape for the age effect. The prior for ros is normal(0,.5), the mean is
not very informative (centered on 0), the sd=0.5 means that the slope
could go from -1 to 1 (2*sd). In a binomial regression context with
standardized explanatory variables, a slope of 1 is considered a strong
effect.</p>
<p><strong>B</strong> Now draw a sample of the joint <em>a priori</em>
distribution of parameters with <code>brm</code>. I suggest specifying
<code>chains = 1, iter = 1500, warmup = 1000</code> to produce a single
Markov chain with 1000 run-in iterations and 500 sample iterations. Then
visualize the distribution of <code>calf</code> predicted for each
iteration of the <em>a priori</em> parameters.</p>
<pre class="r"><code>res_prior &lt;- brm(calf ~ ages+age2+rosNorm +(rosNorm|period),family=bernoulli(&quot;logit&quot;),
    prior = my_prior,sample_prior = &quot;only&quot;,
    data = dat,chains = 1, iter = 3000, warmup = 1000)</code></pre>
<pre class="r"><code>summary(res_prior)</code></pre>
<pre><code>##  Family: bernoulli 
##   Links: mu = logit 
## Formula: calf ~ ages + age2 + rosNorm + (rosNorm | period) 
##    Data: dat (Number of observations: 1922) 
##   Draws: 1 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup draws = 2000
## 
## Group-Level Effects: 
## ~period (Number of levels: 5) 
##                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)              0.80      0.61     0.03     2.26 1.00     1609
## sd(rosNorm)                0.40      0.31     0.01     1.17 1.00     1935
## cor(Intercept,rosNorm)    -0.00      0.58    -0.94     0.96 1.00     3091
##                        Tail_ESS
## sd(Intercept)               943
## sd(rosNorm)                1188
## cor(Intercept,rosNorm)     1002
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.51      1.50    -2.42     3.37 1.00     2586     1502
## ages          0.49      0.25     0.01     0.98 1.00     3377     1347
## age2         -0.50      0.26    -0.99     0.01 1.00     3715     1239
## rosNorm       0.01      0.25    -0.48     0.50 1.00     3602     1447
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<pre class="r"><code>prior_params &lt;- as_draws_df(res_prior) %&gt;% mutate(id=1:n())

hist(prior_params$b_Intercept) # prior on the link scale </code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>hist(plogis(prior_params$b_Intercept)) #prior on  the response scale</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code>hist(prior_params$sd_period__Intercept) </code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-3.png" width="672" /></p>
<pre class="r"><code># simulate predicted response according to 
# the parameter simulated from the prior
prior_pred &lt;- posterior_predict(res_prior) # simulate response variable (calf)
prior_df &lt;- data.frame(prior_pred)[1:200,] # only keep 200 to keep it ligth
prior_df$sim_id &lt;- 1:nrow(prior_df)
prior_df &lt;- pivot_longer(prior_df, cols = -sim_id,
names_to = &quot;obsid&quot;, values_to = &quot;calfprior&quot;) %&gt;%
  mutate(obsid=as.numeric(substr(obsid,2,9))) # pivot it for easier manip  and extrat observation id


# look a the distribution of the prior predicted calf.
# this is not very informative since it&#39;s all 0 or 1
ggplot(prior_df, aes(x = calfprior)) +
stat_density(aes(group = sim_id), position = &quot;identity&quot;, geom = &quot;line&quot;, alpha = 0.3) </code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-4.png" width="672" /></p>
<pre class="r"><code># lets join those prediction with the dataset to look at
# the prior prediction as a function different predictor.
# first age. The priors are more extreme than expected.
# in this casse, its because it is accumulating effects of the intercept
# and the random effects
prior_df &lt;- prior_df %&gt;% left_join(dat)
prior_df %&gt;% ggplot(aes(x=as.factor(round(ages,2)),y=calfprior))+geom_violin()</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-5.png" width="672" /></p>
<pre class="r"><code># but if we look at the average tendencies, they have the right shape
# starting low, going high and then decreasing
ggplot(prior_df,aes(x=age,y=calfprior))+
  geom_smooth(aes(group = sim_id),method=&quot;glm&quot;,formula = y~x+I(x^2),method.args = list(family=&#39;binomial&#39;),se=F,linewidth=0.2)</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-6.png" width="672" /></p>
<pre class="r"><code># we can also look at the prior predictions fort the effect of ros
ggplot(prior_df,aes(x=rosNorm,y=calfprior))+ 
  geom_smooth(aes(group = sim_id),method=&quot;glm&quot;,formula = y~x,method.args = list(family=&#39;binomial&#39;),se=F,linewidth=0.2)</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-7.png" width="672" /></p>
<pre class="r"><code># it can sometime be useful to look at derivative measure not directly modeled.
# they can sometimes reveal unexpected modeling issue
# in this case, lets look at the number of calves per female duroing their life
# the predicted value seem to fit well with the observes value in blue
prior_df %&gt;%group_by(sim_id,id) %&gt;% summarise(calfprior=sum(calfprior)) %&gt;% 
  ggplot(aes(x=calfprior))+
  stat_density(aes(group = sim_id), position = &quot;identity&quot;, geom = &quot;line&quot;, alpha = 0.3)+
  stat_density(data=data.frame(calfprior=tapply(dat$calf,INDEX = dat$id,FUN = sum)),
               aes(x=calfprior),
               position = &quot;identity&quot;,
               geom = &quot;line&quot;, color=&quot;blue&quot;)+
  coord_cartesian(ylim=c(0,1))</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-8.png" width="672" /></p>
<pre class="r"><code># while the prior prediction per age seemed extreme, those by period seem fine
# and end up being pretty vague
prior_df %&gt;%group_by(sim_id,period) %&gt;% summarise(calfprior=mean(calfprior)) %&gt;% 
   ggplot(aes(x=as.factor(period),y=calfprior))+geom_violin()</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-7-9.png" width="672" /></p>
<p>Because of the large number of effects estimated and the fact that we
are imposing only mild constraints on each distribution <em>a
priori</em>, extreme or even impossible values (large positive and
negative values) are to be expected; the important thing is that the
density is larger within a realistic range. It may be useful to “zoom
in” on part of the <code>ggplot</code> by adding
<code>coord_cartesian(xlim = c(..., ...), ylim = c(..., ...))</code>
with limits in <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>.</p>
<p><strong>C</strong> Now fit the model with <code>brm</code>. You can
reduce the number of Markov chains to 2 to save time, but keep the
default values for the number of iterations. (You can ignore the warning
that the effective sample size or ESS is small). How can you evaluate
the convergence of the model?</p>
<pre class="r"><code>res_br &lt;- brm(calf ~ ages+age2+rosNorm +(rosNorm|period),family=bernoulli(&quot;logit&quot;),
    prior = my_prior,iter = 4000,thin=2,
    data = dat,chains = 2)</code></pre>
<pre class="r"><code># as draws esxtracts the posterios (or priors) and arranges them in a df
post_params &lt;- as_draws_df(res_br)


mcmc_plot(res_br, type = &quot;trace&quot;) # see trace plots</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>mcmc_plot(res_br, type = &quot;acf_bar&quot;) # see autocorrelation plots</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
<pre class="r"><code># see parameter esimates and CI (50 and 95%) for a given variable
mcmc_plot(res_br,variable = &#39;r_period&#39;, type = &quot;intervals&quot;)</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-9-3.png" width="672" /></p>
<pre class="r"><code># compare prior to posterior distributions
rbind(
  post_params[,c( &quot;b_Intercept&quot;,&quot;b_ages&quot;,&quot;b_age2&quot;,&quot;b_rosNorm&quot;,
               &quot;sd_period__Intercept&quot;  ,&quot;sd_period__rosNorm&quot;  )] %&gt;% 
  mutate(post=T),
  prior_params[,c( &quot;b_Intercept&quot;,&quot;b_ages&quot;,&quot;b_age2&quot;,&quot;b_rosNorm&quot;,
                &quot;sd_period__Intercept&quot;  ,&quot;sd_period__rosNorm&quot;  )]%&gt;% 
  mutate(post=F)
) %&gt;% pivot_longer(-post) %&gt;% 
  ggplot(aes(x=value))+geom_density(aes(color=post))+facet_wrap(~name,scales = &quot;free_x&quot;)</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-9-4.png" width="672" /></p>
<pre class="r"><code># perform posterior predictive check
pp_check(res_br, type = &quot;stat&quot;, stat = function(x) sum(x == 1))</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-9-5.png" width="672" /></p>
<p>Convergeance seems fine and data was informative enough to change the
posterior compared to the prior. the model had a bit more difficulty
with the random effects and main effect of ros due to the lower
effective sample size ( you really only have 5 ros value for each period
compared to the 2000 points to estimate the effects of age)</p>
<p><strong>D</strong> Compare the magnitude of the `rosNorm’ coefficient
to that of the random effects. What does this comparison tell you?</p>
<pre class="r"><code>summary(res_br)</code></pre>
<pre><code>##  Family: bernoulli 
##   Links: mu = logit 
## Formula: calf ~ ages + age2 + rosNorm + (rosNorm | period) 
##    Data: dat (Number of observations: 1922) 
##   Draws: 2 chains, each with iter = 4000; warmup = 2000; thin = 2;
##          total post-warmup draws = 2000
## 
## Group-Level Effects: 
## ~period (Number of levels: 5) 
##                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)              0.56      0.26     0.24     1.23 1.00     1383
## sd(rosNorm)                0.50      0.20     0.20     0.97 1.00     1294
## cor(Intercept,rosNorm)     0.32      0.40    -0.56     0.91 1.00     1237
##                        Tail_ESS
## sd(Intercept)              1451
## sd(rosNorm)                1641
## cor(Intercept,rosNorm)     1522
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.58      0.29     0.03     1.16 1.00     1141     1215
## ages          0.63      0.06     0.51     0.74 1.00     1852     1746
## age2         -0.67      0.05    -0.78    -0.58 1.00     1919     1811
## rosNorm      -0.30      0.19    -0.63     0.13 1.00     1397     1716
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>the sd of the random slope in large compared to the main effect,
large enough that the different period could have different signs</p>
<p><strong>E</strong> Check posterior: Apply <code>predict</code> to the
model to get the mean, standard deviation and 95% interval for the
<em>hindcast</em> prediction. You can give a data.frame to the newdata
argument to get the desired predictions
(<code>expand.grid(rosNorm=seq(-1.6,1.6,l=30),period=unique(dat$period),...)</code>).
Illustrate the model predictions and their credibility intervals for the
different periods for a 7 year old individual.</p>
<pre class="r"><code># we make the first prediction by changing all age to 0,
# in effect controlling for this nuisance variable
# the re_formula lets us chose which random effect to account for in the prediction
post_pred &lt;- posterior_epred(res_br,
                              newdata = mutate(dat,ages=0,age2=0),
                              re_formula =~(rosNorm|period))
dat$y=apply(post_pred,2,mean)
dat$y.sd=apply(post_pred,2,sd)
dat$ymin=apply(post_pred,2,function(x) quantile(x,0.025))
dat$ymax=apply(post_pred,2,function(x) quantile(x,0.975))
pt &lt;- dat %&gt;% group_by(period,year) %&gt;% summarise_if(is.numeric,mean)
# we can also start from a whole new dataframe, by using a sequence from 
# the minimum to maximum observed ros (l= length.out= length of this sequence)
# this will allow us to enough points that if we link them, 
# it looks like a prediction line
newd=expand.grid(ages=0,age2=0,rosNorm=seq(-1.6,1.6,l=30),period=unique(dat$period),id=&quot;W16&quot;)
post_pred2 &lt;- posterior_epred(res_br,newdata =newd, re_formula =~(rosNorm|period) )
newd$y=apply(post_pred2,2,mean)
newd$y.sd=apply(post_pred2,2,sd)
newd$ymin=apply(post_pred2,2,function(x) quantile(x,0.025))
newd$ymax=apply(post_pred2,2,function(x) quantile(x,0.975))


ggplot(newd,aes(x=rosNorm,y=y))+
  geom_point(data=pt)+
  geom_ribbon(aes(fill=period,ymin=ymin,ymax=ymax),alpha=0.2)+
  geom_path(aes(color=period))</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code># we can do the same to illustrate the effect of age while controling for the 
# effect of ros
post_pred &lt;- posterior_epred(res_br,
                              newdata = mutate(dat,rosNorm=0),
                              re_formula =NA)
dat$y=apply(post_pred,2,mean)
dat$y.sd=apply(post_pred,2,sd)
dat$ymin=apply(post_pred,2,function(x) quantile(x,0.025))
dat$ymax=apply(post_pred,2,function(x) quantile(x,0.975))
pt &lt;- dat %&gt;% group_by(period,age,year) %&gt;% summarise_if(is.numeric,mean)

newd=dat %&gt;% select(age,ages,age2) %&gt;% unique() %&gt;% mutate(rosNorm=0)
post_pred2 &lt;- posterior_epred(res_br,newdata =newd, re_formula =NA)
newd$y=apply(post_pred2,2,mean)
newd$y.sd=apply(post_pred2,2,sd)
newd$ymin=apply(post_pred2,2,function(x) quantile(x,0.025))
newd$ymax=apply(post_pred2,2,function(x) quantile(x,0.975))

ggplot(newd)+
  stat_summary(data=pt,aes(x=age,y=calf),fun.data = &#39;mean_cl_boot&#39;,geom=&#39;pointrange&#39;)+
  geom_ribbon(aes(x=age,y=y,ymin=ymin,ymax=ymax),alpha=0.2)+
  geom_line(aes(x=age,y=y,ymin=ymin,ymax=ymax))</code></pre>
<pre><code>## Warning in geom_line(aes(x = age, y = y, ymin = ymin, ymax = ymax)): Ignoring
## unknown aesthetics: ymin and ymax</code></pre>
<p><img src="09bER-Modeles_bayesiens2_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
