<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Introduction to Bayesian analysis</title>

<script src="libs/header-attrs-2.20/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div id="header">



<h1 class="title toc-ignore">Introduction to Bayesian analysis</h1>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This class presents the basic concepts of the Bayesian approach to
parameter estimation, in preparation for the use of hierarchical
Bayesian models in the next two weeks.</p>
<p>We begin with a presentation of conditional probability theory and
Bayes theorem, a topic that is not specific to Bayesian inference, but
will be useful in understanding the logic of this approach.</p>
</div>
<div id="contents" class="section level1">
<h1>Contents</h1>
<ul>
<li><p>Conditional probability</p></li>
<li><p>Bayesian inference</p></li>
<li><p>Example of Bayesian regression</p></li>
<li><p>Visualize and verify the fit of a model</p></li>
</ul>
</div>
<div id="conditional-probability" class="section level1">
<h1>Conditional probability</h1>
<div id="example" class="section level2">
<h2>Example</h2>
<p>Suppose a new test is designed to detect a disease by measuring the
concentration of a certain protein in the blood. This concentration is
higher on average in people with the disease than in people without the
disease, but it is not possible to distinguish between the two groups
perfectly. Clinical studies have estimated the following two properties
of this test:</p>
<ul>
<li><p>The sensitivity of the test, i.e. the probability of obtaining a
positive result if the disease is present, is 95%.</p></li>
<li><p>The specificity of the test, i.e. the probability of obtaining a
negative result if the disease is absent, is 99%.</p></li>
</ul>
<p>Based on this information, can we determine the probability of having
the disease if we receive a positive result?</p>
<p>As we will see below, this probability depends on the general
prevalence of the disease in the population tested. Therefore, let’s
assume that 0.2% of the tested population has the disease.</p>
<p>With this information, we can divide the tested population into 4
groups according to whether the disease is present (<span
class="math inline">\(M_1\)</span>) or not (<span
class="math inline">\(M_0\)</span>) and whether the test is positive
(<span class="math inline">\(T_+\)</span>) or negative (<span
class="math inline">\(T_-\)</span>). Out of 10,000 people receiving the
test, we can calculate that on average:</p>
<ul>
<li><p>0.2% x 10,000 = 20 will be affected.</p></li>
<li><p>Out of 20 people affected, on average 95% x 20 = 19 will receive
a positive result, and 1 will receive a negative result.</p></li>
<li><p>Out of 9980 people not affected, on average 1% x 9980 = 99.8
(rounded to 100) will receive a positive result and the other 9880 will
receive a negative result.</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Affected: <span
class="math inline">\(M_1\)</span></th>
<th align="right">Not affected: <span
class="math inline">\(M_0\)</span></th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Positive test: <span class="math inline">\(T_+\)</span></td>
<td align="right">19</td>
<td align="right">100</td>
<td align="right">119</td>
</tr>
<tr class="even">
<td>Negative test: <span class="math inline">\(T_-\)</span></td>
<td align="right">1</td>
<td align="right">9880</td>
<td align="right">9881</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right">20</td>
<td align="right">9980</td>
<td align="right">10000</td>
</tr>
</tbody>
</table>
<p>Therefore, out of the 119 people receiving a positive result on
average, 19 / 119 = about 16% have the disease. Among those who receive
a negative result, 1 / 9881 = about 0.01% are affected.</p>
<p>In the following section, we repeat this calculation using the
concept of conditional probability.</p>
</div>
<div id="definitions" class="section level2">
<h2>Definitions</h2>
<div id="conditional-probability-1" class="section level3">
<h3>Conditional probability</h3>
<p>If <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> are two random variables, the
conditional probability <span class="math inline">\(p(y|x)\)</span> is
the probability of <span class="math inline">\(y\)</span> for a given
value of <span class="math inline">\(x\)</span> (also called the
probability of <span class="math inline">\(y\)</span> given <span
class="math inline">\(x\)</span>).</p>
<p>In our example, we have two variables: <span
class="math inline">\(M\)</span> represents the presence or absence of
the disease and <span class="math inline">\(T\)</span> represents the
positive or negative test result. The sensitivity of the test is the
probability of <span class="math inline">\(T_+\)</span> if the person is
known to have the disease, i.e. <span class="math inline">\(P(T_+ |
M_1)\)</span>, equal to 0.95. The specificity represents the conditional
probability <span class="math inline">\(P(T_- | M_0)\)</span>, equal to
0.99.</p>
</div>
<div id="joint-probability" class="section level3">
<h3>Joint probability</h3>
<p>The joint probability of obtaining both a certain value of <span
class="math inline">\(x\)</span> and a certain value of <span
class="math inline">\(y\)</span>, denoted <span
class="math inline">\(p(x, y)\)</span>, can be calculated in two ways:
(1) the probability of obtaining <span class="math inline">\(x\)</span>
multiplied by the probability of obtaining <span
class="math inline">\(y\)</span>, given <span
class="math inline">\(x\)</span>; or (2) the probability of obtaining
<span class="math inline">\(y\)</span> multiplied by the probability of
obtaining <span class="math inline">\(x\)</span>, given <span
class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[p(x, y) = p(x) p(y | x) = p(y) p(x |
y)\]</span></p>
<p>In our example, here are the two ways to calculate the probability of
having the disease <em>and</em> getting a positive test:</p>
<p><span class="math display">\[p(M_1, T_+) = p(M_1) p(T_+ | M_1) =
p(T_+) p(M_1 | T_+)\]</span></p>
</div>
<div id="marginal-probability" class="section level3">
<h3>Marginal probability</h3>
<p>The marginal probability of a variable <span
class="math inline">\(y\)</span>, <span
class="math inline">\(p(y)\)</span>, is its probability if the value of
the other variables is unknown. If we do not directly know <span
class="math inline">\(p(y)\)</span>, but know <span
class="math inline">\(p(y, x)\)</span> for each possible value of
another variable <span class="math inline">\(x\)</span>, then <span
class="math inline">\(p(y)\)</span> is the sum of the joint
probabilities of <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> for each value of <span
class="math inline">\(x\)</span>. (<em>Marginalization</em> is the
action of summing up the different possibilities for variables other
than <span class="math inline">\(y\)</span>).</p>
<p><span class="math display">\[p(y) = \sum_x p(y, x) = \sum_x p(y|x)
p(x)\]</span></p>
<p>If <span class="math inline">\(x\)</span> is a continuous variable,
the principle is the same, but the sum becomes an integral:</p>
<p><span class="math display">\[p(y) = \int p(y, x) \text{d}x = \int
p(y|x) p(x) \text{d}x\]</span></p>
<p>Returning to our example, we can express each item in the table as a
joint probability with specific values of <span
class="math inline">\(M\)</span> or <span
class="math inline">\(T\)</span> (inner cells), or as a marginal
probability (for the row and column sums).</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right"><span class="math inline">\(M_1\)</span></th>
<th align="right"><span class="math inline">\(M_0\)</span></th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(T_+\)</span></td>
<td align="right"><span class="math inline">\(p(M_1, T_+)\)</span></td>
<td align="right"><span class="math inline">\(p(M_0, T_+)\)</span></td>
<td align="right"><span class="math inline">\(p(T_+)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(T_-\)</span></td>
<td align="right"><span class="math inline">\(p(M_1, T_-)\)</span></td>
<td align="right"><span class="math inline">\(p(M_0, T_-)\)</span></td>
<td align="right"><span class="math inline">\(p(T_-)\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right"><span class="math inline">\(p(M_1)\)</span></td>
<td align="right"><span class="math inline">\(p(M_0)\)</span></td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>This allows us to fill in the cells in the table using the
relationship between conditional, joint, and marginal probabilities. For
example, for the row <span class="math inline">\(T_+\)</span>:</p>
<ul>
<li><p><span class="math inline">\(p(M_1, T_+) = p(M_1) p(T_+ | M_1) =
0.002 \times 0.95 = 0.0019\)</span></p></li>
<li><p><span class="math inline">\(p(M_0, T_+) = p(M_0) p(T_+ | M_0) =
0.998 \times 0.01 = 0.00998\)</span> (<span class="math inline">\(p(T_+
| M_0)\)</span> is the probability to get a false positive, so the
complement of specificity, equal to 1%.)</p></li>
<li><p><span class="math inline">\(p(T_+) = p(M_1, T_+) + p(M_0, T_+) =
0.019 + 0.00998 \approx 0.119\)</span></p></li>
</ul>
<p>Here is the full table:</p>
<table>
<colgroup>
<col width="18%" />
<col width="27%" />
<col width="22%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th align="right"><span class="math inline">\(M_1\)</span></th>
<th align="right"><span class="math inline">\(M_0\)</span></th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(T_+\)</span></td>
<td align="right"><span class="math inline">\(p(M_1, T_+)\)</span> =
0.0019</td>
<td align="right"><span class="math inline">\(p(M_0, T_+)\)</span> =
0.01</td>
<td align="right"><span class="math inline">\(p(T_+)\)</span> =
0.0119</td>
</tr>
<tr class="even">
<td><span class="math inline">\(T_-\)</span></td>
<td align="right"><span class="math inline">\(p(M_1, T_-)\)</span> =
0.0001</td>
<td align="right"><span class="math inline">\(p(M_0, T_-)\)</span> =
0.988</td>
<td align="right"><span class="math inline">\(p(T_-)\)</span> =
0.9881</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="right"><span class="math inline">\(p(M_1)\)</span> =
0.002</td>
<td align="right"><span class="math inline">\(p(M_0)\)</span> =
0.998</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bayes-theorem" class="section level2">
<h2>Bayes’ theorem</h2>
<p>For two variables <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>, it may be easier to calculate <span
class="math inline">\(p(y|x)\)</span> than <span
class="math inline">\(p(x|y)\)</span>, or vice versa. In our example, we
knew the probability of having a positive result if the disease is
present <span class="math inline">\(p(T_+ | M_1)\)</span>, but we were
looking for the probability that the disease is present if the result is
positive: <span class="math inline">\(p(M_1 | T_+)\)</span>. Bayes’
theorem tells us how to “invert” the conditional probability without
having to fill in a table like the one above.</p>
<p>Remember that there are two ways to compute the joint probability
<span class="math inline">\(p(x, y)\)</span> with a value of <span
class="math inline">\(x\)</span> and a value of <span
class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[p(x, y) = p(x) p(y | x) = p(y) p(x |
y)\]</span></p>
<p>If we divide both sides of the right equality by <span
class="math inline">\(p(y)\)</span>, we obtain Bayes’ theorem:</p>
<p><span class="math display">\[p(x|y) = \frac{p(x) p(y |
x)}{p(y)}\]</span></p>
<p>This tells us that we can compute the probability distribution from
<span class="math inline">\(x\)</span> conditional on <span
class="math inline">\(y\)</span> if we know: (1) the probability
distribution of <span class="math inline">\(y\)</span> conditional on
<span class="math inline">\(x\)</span> and (2) the marginal probability
distribution of <span class="math inline">\(x\)</span>. As for the
denominator <span class="math inline">\(p(y)\)</span>, it can be
obtained by summing (or integrating) <span class="math inline">\(p(x)
p(y|x)\)</span> over the set of possible values of <span
class="math inline">\(x\)</span>.</p>
<p>In our example, the application of the theorem shows that <span
class="math inline">\(p(M_1 | T_+)\)</span> = 16%, as previously
determined.</p>
<p><span class="math display">\[p(M_1 | T_+) = \frac{p(T_+ | M_1)
p(M_1)}{p(T_+)}\]</span></p>
<p>–</p>
<p><span class="math display">\[p(M_1 | T_+) = \frac{p(T_+ | M_1)
p(M_1)}{p(T_+ | M_1) p(M_1) + p(T_+ | M_0) p(M_0)}\]</span></p>
<p><span class="math display">\[p(M_1 | T_+) = \frac{0.95 \times
0.002}{0.95 \times 0.002 + 0.01 \times 0.998} = 0.16\]</span></p>
<p>Note that with a positive result, the probability of having the
disease is multiplied by 80 (16% vs. 0.2%), but it is still more likely
to not have it. In other words, if a disease is quite rare, most
positive results will be false positives. This is why some tests are not
performed without the presence of other symptoms that would increase the
probability of being affected before the test. The question of whether
or not to perform a test is sometimes a difficult ethical decision,
because both a lack of detection or a false alarm have harmful
effects.</p>
<p>Similarly, one could calculate <span class="math inline">\(p(M_1 |
T_-)\)</span> = 0.01%. So with a negative result, the probability of
being affected is divided by 20 relative to the general prevalence of
the disease.</p>
<p>By rearranging the terms of Bayes’ theorem:</p>
<p><span class="math display">\[p(M_1 | T_+) = \frac{p(T_+ |
M_1)}{p(T_+)}  p(M_1)\]</span></p>
<p>we see that it is a method to revise an initial probability <span
class="math inline">\(p(M_1)\)</span> according to new information given
by the test result, to obtain a probability <span
class="math inline">\(p(M_1 | T_+)\)</span>. This idea is the basis of
Bayesian inference.</p>
</div>
</div>
<div id="bayesian-inference" class="section level1">
<h1>Bayesian inference</h1>
<div id="frequentist-and-bayesian-interpretations"
class="section level2">
<h2>Frequentist and Bayesian interpretations</h2>
<p>In the previous section, we saw how Bayes’ theorem allows us to
calculate the probability of having a disease based on its general
prevalence <span class="math inline">\(p(M_1)\)</span> and the result of
a screening test, <span class="math inline">\(T_+\)</span> or <span
class="math inline">\(T_-\)</span>:</p>
<p><span class="math display">\[p(M_1 | T_+) = \frac{p(T_+ |
M_1)}{p(T_+)}  p(M_1)\]</span> <span class="math display">\[p(M_1 | T_-)
= \frac{p(T_- | M_1)}{p(T_-)}  p(M_1)\]</span></p>
<p>Now consider <span class="math inline">\(M_1\)</span> as a hypothesis
that a given patient has the disease. The <em>prior</em> probability of
<span class="math inline">\(M_1\)</span> (before the test) is equal to
<span class="math inline">\(p(M_1)\)</span>. After the test, the
<em>posterior</em> probability of <span
class="math inline">\(M_1\)</span> is <span class="math inline">\(p(M_1
| T_+)\)</span> or <span class="math inline">\(p(M_1 | T_-)\)</span>,
depending on the result.</p>
<p>According to the <strong>frequentist</strong> interpretation,
probabilities represent the frequency of events after a large number of
repetitions of an observation or experiment. In this case, we can assign
a probability to <span class="math inline">\(M_1\)</span> because the
patient comes from a population and the disease has a certain frequency
in that population.</p>
<p>Frequentist interpretation is the basis of most introductory
statistics courses, as it allows, among other things, the definition of
hypothesis tests and confidence intervals. In this approach, a
probability can be assigned to statistics based on observed data, such
as the mean of a sample <span class="math inline">\(\bar{x}\)</span>,
but not to model parameters such as the population mean <span
class="math inline">\(\mu\)</span>. When defining a 95% confidence
interval around <span class="math inline">\(\bar{x}\)</span>, it is not
that this particular interval that has a 95% probability of containing
<span class="math inline">\(\mu\)</span> (after sampling, the interval
and <span class="math inline">\(\mu\)</span> are both fixed), but it is
95% of the possible samples of <span class="math inline">\(x\)</span>
that would produce an interval containing the value of <span
class="math inline">\(\mu\)</span>.</p>
<p>According to the <strong>Bayesian</strong> interpretation,
probabilities represent our uncertainty about the value of a quantity.
We can therefore speak of a probability distribution even for a presumed
fixed value, e.g. a parameter of a model.</p>
<p>Historically, debates between the two approaches have often been
acrimonious. Today, the same statisticians may use either the
frequentist or the Bayesian approach depending on the nature of the
problem. However, care must be taken to ensure that the results are
always interpreted according to the approach used. Remember, for
example, that a frequentist confidence interval does not represent a
probability distribution of the parameter, or that checking the fit of a
Bayesian model is not equivalent to a null hypothesis test.</p>
</div>
<div id="bayesian-inference-on-the-value-of-a-parameter"
class="section level2">
<h2>Bayesian inference on the value of a parameter</h2>
<p>Suppose we have a series of observations of a variable <span
class="math inline">\(y\)</span>, which we represent by a model
including an adjustable parameter <span
class="math inline">\(\theta\)</span>. In the Bayesian approach, we
assign a prior probability distribution to <span
class="math inline">\(\theta\)</span>, <span
class="math inline">\(p(\theta)\)</span>, representing the uncertainty
on the value of the parameter before having observed the data. The
probability of the observations <span class="math inline">\(y\)</span>,
conditional on a given value of <span
class="math inline">\(\theta\)</span>, is given by the likelihood
function <span class="math inline">\(p(y|\theta)\)</span>.</p>
<p>From this information, we can use Bayes’ theorem to infer <span
class="math inline">\(p(\theta | y)\)</span>, which is the posterior
distribution of <span class="math inline">\(\theta\)</span> after
observing <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[p(\theta | y) = \frac{p(y | \theta)
p(\theta)}{p(y)}\]</span></p>
<p>The denominator <span class="math inline">\(p(y)\)</span> is obtained
by summing (or integrating) <span class="math inline">\(p(y | \theta)
p(\theta)\)</span> for all possible values of <span
class="math inline">\(\theta\)</span>. Most of the time, this quantity
cannot be calculated exactly, but it is approximated by the Monte-Carlo
methods that we will see in the next lesson.</p>
</div>
<div id="example-1" class="section level2">
<h2>Example</h2>
<p>Here is a simple example to illustrate the principle of Bayesian
inference. Suppose that ten throws of a coin produce the following
series of values (0 = tails, 1 = heads): 0,0,0,0,0,0,0,1,1,1,1,0,0,0. We
try to estimate <span class="math inline">\(p\)</span>, the probability
of getting “heads” for this coin.</p>
<p>If <span class="math inline">\(y\)</span> is the number of “heads”
obtained among <span class="math inline">\(n\)</span> throws, then the
likelihood function is given by the binomial distribution: <span
class="math inline">\(y \sim \text{Bin}(n, p)\)</span>.</p>
<p>The different panels of the graph below show the posterior
distribution of <span class="math inline">\(p\)</span> (solid line)
after each throw in the sequence. In this case, the prior distribution
indicated by the dotted line was very diffuse, giving an equal
probability to each possible value of <span
class="math inline">\(p\)</span>. After 10 throws, the maximum of the
posterior distribution is equal to the proportion of “heads” in the data
(0.3), which is also the maximum likelihood estimate.</p>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>The graph below shows the same inference, but with a prior
distribution much more concentrated around 0.5. This distribution
represents the idea that a coin is much more likely to be balanced (50%
heads) and that deviations around this value are generally minor. In
this case, the posterior distribution moves with the data, but remains
much closer to the prior distribution.</p>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Finally, the graph below compares the posterior distribution (orange
line) according to each prior distribution (dotted line). The likelihood
(identical in both cases) is indicated by a solid line and has been
normalized to be compared to the distributions.</p>
<p>For the diffuse prior distribution (left), the posterior distribution
is exactly proportional to the likelihood. When the prior distribution
is more concentrated than the likelihood (right), the posterior
distribution is in between, but closer to the prior distribution.</p>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="choosing-the-prior-distribution" class="section level2">
<h2>Choosing the prior distribution</h2>
<p>In some cases, prior knowledge can give us a fairly specific idea of
the prior distribution to use. For example, the posterior distribution
obtained from one study can be used as the prior distribution for a
subsequent study.</p>
<p>More often, however, we can use a fairly diffuse distribution to
penalize very implausible parameter values without unduly constraining
the analysis. The term <em>weakly informative prior</em> describes this
type of choice.</p>
<p>A common criticism of Bayesian inference is that assigning a prior
distribution adds bias to the analysis. However, if the choice of this
distribution is justified by the need to penalize too extreme values of
the parameters, the role of the prior distribution is not so different
from that of a random effect that shrinks the group means towards the
general mean, or of the smoothing parameter in an additive model that
penalizes too complex curves. All these methods are examples of
<em>regularization</em>, i.e. the imposition of constraints that control
the risk of overfitting in a complex model, without having to completely
fix certain parameters and effects.</p>
<p>The choice of the prior distribution can be considered as an
assumption in addition to the other assumptions of the model, such as
the choice of the distribution representing the observations, the choice
of the predictors and interactions to be included or excluded in the
model, etc. Ultimately, it is the entire model that must be validated
for its ability to reproduce the characteristics of the observations,
including observations other than those used to fit the model.</p>
</div>
<div id="advantages-and-disadvantages-of-the-bayesian-approach"
class="section level2">
<h2>Advantages and disadvantages of the Bayesian approach</h2>
<p>Like maximum likelihood, Bayesian inference has the advantage of
being applicable to any type of <em>generative model</em>, i.e. a model
that mathematically describes how observations are generated from
parameters. In a Bayesian approach, the parameters of various types of
models, including all those seen in this course (generalized linear,
mixed effects, additive, time-dependent and spatially-dependent models)
can be estimated using the same algorithms; we will discuss these
algorithms further in the next class. These algorithms produce the joint
posterior distribution of the parameters of the model, from which we can
easily obtain the distribution of any quantity derived from the model:
combination of parameters, prediction, etc. By way of comparison,
maximum likelihood only tells us the value of each parameter maximizing
the likelihood, and obtaining confidence intervals on values derived
from several parameters can be very laborious. On the other hand,
Bayesian methods produce more information, but require much more
computational resources.</p>
<p>From the model design point of view, the Bayesian approach is also
more demanding, since a prior distribution must be specified for each
adjustable parameter. As mentioned above, these prior distributions are
nevertheless useful for stabilizing the estimation of complex models;
when data are limited, constraining the value of the effects may be a
better solution than simply eliminating these effects from the
model.</p>
</div>
</div>
<div id="bayesian-regression-example" class="section level1">
<h1>Bayesian regression example</h1>
<p>To illustrate the Bayesian approach, we will estimate here the
relationship between the number of plant species and the area of 30
islands of the Galapagos Archipelago, from the <a
href="../donnees/galapagos.csv">galapagos.csv</a> dataset already seen
in this course.</p>
<pre class="r"><code>galap &lt;- read.csv(&quot;../donnees/galapagos.csv&quot;)
head(galap)</code></pre>
<pre><code>##           Name Species Endemics  Area Elevation Nearest Scruz Adjacent
## 1       Baltra      58       23 25.09       346     0.6   0.6     1.84
## 2    Bartolome      31       21  1.24       109     0.6  26.3   572.33
## 3     Caldwell       3        3  0.21       114     2.8  58.7     0.78
## 4     Champion      25        9  0.10        46     1.9  47.4     0.18
## 5      Coamano       2        1  0.05        77     1.9   1.9   903.82
## 6 Daphne.Major      18       11  0.34       119     8.0   8.0     1.84</code></pre>
<p>The number of species per island varies between 2 and 444, while the
surface area of the islands varies on several orders of magnitude, from
0.01 to 5000 km<span class="math inline">\(^2\)</span>.</p>
<pre class="r"><code>summary(galap$Species)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    2.00   13.00   42.00   85.23   96.00  444.00</code></pre>
<pre class="r"><code>summary(galap$Area)</code></pre>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##    0.010    0.258    2.590  261.709   59.238 4669.320</code></pre>
<p>We assume that the number of species <span
class="math inline">\(S\)</span> follows a Poisson distribution, where
the logarithm of the mean number of species varies with the logarithm of
the area <span class="math inline">\(A\)</span>.</p>
<p><span class="math display">\[S \sim \text{Pois}(\lambda)\]</span></p>
<p><span class="math display">\[\log \lambda = \beta_0 + \beta_1 \log
A\]</span></p>
<p>This last equation is equivalent to a power law (with exponent <span
class="math inline">\(\beta_1\)</span>) linking <span
class="math inline">\(\lambda\)</span> and <span
class="math inline">\(A\)</span>.</p>
<p><span class="math display">\[\lambda = e^{\beta_0}
A^{\beta_1}\]</span></p>
<div id="choice-of-prior-distributions" class="section level2">
<h2>Choice of prior distributions</h2>
<p>In the above equation, <span class="math inline">\(\beta_1\)</span>
is the exponent of the relationship between the number of species and
the area of an island. In order to choose a prior distribution, we first
assume that <span class="math inline">\(\beta_1 \ge 0\)</span>, due to a
theoretical argument that a larger area cannot have a negative effect on
the mean number of species. This does not mean that a larger island
cannot have fewer species; only that it cannot have fewer species
<em>because</em> of its larger area. Also, since <span
class="math inline">\(\beta_1 = 1\)</span> represents a linear
relationship between <span class="math inline">\(S\)</span> and <span
class="math inline">\(A\)</span>, a value of <span
class="math inline">\(\beta_1 &gt; 1\)</span> would mean that the effect
of adding an extra km<span class="math inline">\(^2\)</span> on <span
class="math inline">\(S\)</span> is greater for a large island (e.g.:
quadratic relationship with <span class="math inline">\(\beta =
2\)</span>). On the contrary, we assume that it is more plausible than
<span class="math inline">\(\beta_1 &lt; 1\)</span>, because the
addition of one km<span class="math inline">\(^2\)</span> should have
more effect on the number of species if the island is small than if it
is already very large.</p>
<p>In this case, we choose as a prior distribution for <span
class="math inline">\(\beta_1\)</span> an exponential distribution with
a parameter of 4: <span class="math inline">\(\beta_1 \sim
\text{Exp}(4)\)</span>. The exponential distribution has a maximum at 0
and decreases exponentially; the rate of this decrease is given by the
adjustable parameter. Here, with a parameter of 4 we have about 2%
probability that <span class="math inline">\(\beta_1 &gt; 1\)</span>.
Thus, values greater than 1 are considered improbable but not
impossible.</p>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>As for the intercept <span class="math inline">\(\beta_0\)</span>, it
is the logarithm of the mean number of species when <span
class="math inline">\(\log A = 0\)</span>, i.e. when the area is 1
km<span class="math inline">\(^2\)</span>.</p>
<p><em>Note</em>: The <em>brms</em> package we will use transforms the
regression predictors to center them on their mean value. It does not
affect the results produced for the regression, but it requires that we
specify a prior distribution not for <span
class="math inline">\(\beta_0\)</span> as defined here, but for an
intercept that would represent the mean value of the response if the
predictors were at their mean value. In other words, we are looking for
a prior distribution of the log of the number of species for an island
with an average log area.</p>
<p>Suppose that the plausible values for the number of species of the
mean island are between 1 and 1000. Taking the log of these values, we
obtain <span class="math inline">\(\log(1) = 0\)</span> and <span
class="math inline">\(\log(1000) = 6.91\)</span>. In this case, we
choose a prior normal distribution, with a mean of 3 and standard
deviation of 2: <span class="math inline">\(\beta_0 \sim \text{N}(3,
2)\)</span>. This places about 95% of the probability between -1 and
7.</p>
</div>
<div id="possible-regression-lines-from-the-prior"
class="section level2">
<h2>Possible regression lines from the prior</h2>
<p>To see if our prior distributions cover the plausible scenarios for
our model, it is useful to simulate the predictions made by these
distributions. In the R code below, we first create a
<code>sim_df</code> data set containing 100 values of <span
class="math inline">\(\beta_0\)</span> and <span
class="math inline">\(\beta_1\)</span> drawn from their prior
distributions, with an index <em>i</em> identifying the simulation. We
then create a grid associating to each simulation number a geometric
series of values of the area (between 0.01 km<span
class="math inline">\(^2\)</span> and 10 000 km<span
class="math inline">\(^2\)</span>) to make the predictions. Finally, we
combine the two sets of data and calculate the predicted <span
class="math inline">\(\lambda\)</span> value for each area for each of
the 100 simulations.</p>
<pre class="r"><code>library(dplyr)

# 100 simulations of parameters b0 et b1
sim_df &lt;- data.frame(i = 1:100, b0 = rnorm(100, 3, 2), b1 = rexp(100, 4))

# Grid with different values of the area for each simulation
grille &lt;- expand.grid(i = 1:100, area = c(0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 
                                          100, 300, 1000, 3000, 10000))

# Mean number of species for each simulation 
sim_df &lt;- inner_join(sim_df, grille) %&gt;%
    mutate(lambda = exp(b0 + b1 * log(area)))

head(sim_df)</code></pre>
<pre><code>##   i       b0         b1 area   lambda
## 1 1 0.580099 0.08847682 0.01 1.188448
## 2 1 0.580099 0.08847682 0.03 1.309768
## 3 1 0.580099 0.08847682 0.10 1.456991
## 4 1 0.580099 0.08847682 0.30 1.605725
## 5 1 0.580099 0.08847682 1.00 1.786215
## 6 1 0.580099 0.08847682 3.00 1.968557</code></pre>
<p>Here are the regression lines from 100 simulations based on the prior
distributions:</p>
<pre class="r"><code>ggplot(sim_df, aes(x = area, y = lambda, group = i)) +
    labs(x = &quot;A&quot;, y = expression(lambda)) +
    geom_line(alpha = 0.3) +
    scale_x_log10(label = scales::number_format(accuracy = 0.1)) +
    scale_y_log10(label = scales::number_format(accuracy = 0.1))</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>We can see that these lines cover a very wide range of possibilities,
some even implausible (the steepest line has a fraction of a species for
the smallest island up to more than 100,000 species for the
largest).</p>
</div>
</div>
<div id="bayesian-regression-with-brms." class="section level1">
<h1>Bayesian regression with <em>brms</em>.</h1>
<p>The <em>brms</em> package, which is an acronym for <em>Bayesian
Regression Models using Stan</em>, allows us to fit various regression
models using the Bayesian approach. The advantage of this package is
that it allows us to specify a wide range of models, including almost
all types of parametric models seen in this course (e.g. GLMM, GAMM,
models with temporal and spatial dependence). The model specification
uses the same type of formula as the other R packages, then
<em>brms</em> automatically translates the specified models into the
language used by the Bayesian inference program <em>Stan</em>, which we
will present in the next class.</p>
<p>In this package, the <code>brm</code> function is used to fit a
regression model.</p>
<pre class="r"><code>library(brms)
bmod &lt;- brm(Species ~ log(Area), data = galap, family = poisson, 
            prior = c(set_prior(&quot;normal(3, 2)&quot;, class = &quot;Intercept&quot;),
                      set_prior(&quot;exponential(4)&quot;, class = &quot;b&quot;, lb = 0)))</code></pre>
<p>The first line looks like a classic GLM specification, while the
other lines define the prior distributions for each parameter. The
intercept (<code>class = "Intercept"</code>) receives a normal
distribution with a mean of 3 and a standard deviation of 2, while the
other regression coefficients (<code>class = "b"</code>) - there is only
one here - receive an exponential distribution of parameter 4.</p>
<p><em>Notes</em>: - The specification of the distributions,
e.g. “normal(3, 2)” is based on the syntax of the <a
href="https://mc-stan.org">Stan</a> language. - The argument
<code>lb = 0</code> (for <em>lower bound</em>) is needed here, because
the exponential prior distribution is only valid for values greater than
or equal to 0.</p>
<p>Here is the summary of the model results:</p>
<pre class="r"><code>summary(bmod)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: Species ~ log(Area) 
##    Data: galap (Number of observations: 30) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.27      0.04     3.19     3.35 1.01      966     1165
## logArea       0.34      0.01     0.32     0.35 1.01     1060     1253
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Many of the information given here are related to the Bayesian
inference algorithm, which we will discuss in the next class. The
<code>Estimate</code> and <code>Est. Error</code> columns give
respectively the mean (3.27 and 0.34) and the standard deviation (0.04
and 0.01) of the posterior distribution of the coefficients. These
results are in fact identical to those obtained with a classical GLM, as
we can see below.</p>
<pre class="r"><code>gmod &lt;- glm(Species ~ log(Area), data = galap, family = poisson)
summary(gmod)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Species ~ log(Area), family = poisson, data = galap)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -10.4688   -3.6073   -0.8874    2.9028   10.1517  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) 3.273200   0.041663   78.56   &lt;2e-16 ***
## log(Area)   0.337737   0.007154   47.21   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 3510.73  on 29  degrees of freedom
## Residual deviance:  651.67  on 28  degrees of freedom
## AIC: 816.5
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>We have here a simple model with sufficient data, so the influence of
the prior distribution is negligible and both methods (Bayesian
inference and maximum likelihood) lead to the same conclusion.
Nevertheless, the purpose of this exercise was to illustrate how we
could choose prior distributions for a real data set.</p>
</div>
<div id="visualize-and-verify-the-fit-of-the-model"
class="section level1">
<h1>Visualize and verify the fit of the model</h1>
<div id="estimated-effects-and-credible-intervals"
class="section level2">
<h2>Estimated effects and credible intervals</h2>
<p>Let us return to the summary of the results of our Bayesian
regression:</p>
<pre class="r"><code>summary(bmod)</code></pre>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: Species ~ log(Area) 
##    Data: galap (Number of observations: 30) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.27      0.04     3.19     3.35 1.01      966     1165
## logArea       0.34      0.01     0.32     0.35 1.01     1060     1253
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The <em>Population-Level Effects</em> section describes the fixed
effects of the model (there are no random effects here). The same
information can be obtained with <code>fixef</code>.</p>
<pre class="r"><code>fixef(bmod)</code></pre>
<pre><code>##            Estimate   Est.Error      Q2.5     Q97.5
## Intercept 3.2729939 0.041759005 3.1889537 3.3533968
## logArea   0.3377133 0.007136395 0.3237503 0.3518799</code></pre>
<p>By default, the estimate is the posterior mean of the parameter and
the error is its standard deviation. However, more robust estimates can
be chosen. With the specification <code>robust = TRUE</code>, R gives us
an estimate based on the median and an error based on the median
absolute deviation.</p>
<pre class="r"><code>fixef(bmod, robust = TRUE)</code></pre>
<pre><code>##            Estimate   Est.Error      Q2.5     Q97.5
## Intercept 3.2728540 0.041719262 3.1889537 3.3533968
## logArea   0.3378113 0.007207817 0.3237503 0.3518799</code></pre>
<p>In this case, the posterior distribution is probably close to a
normal distribution, so that the robust and non-robust estimates are
almost identical.</p>
<p>The 2.5% and 97.5% quantiles presented in this summary define a
<em>credible interval</em> containing 95% of the posterior probability
distribution of the parameter. These intervals are the Bayesian
analogues of the confidence intervals.</p>
<p>The function <code>marginal_effects</code> allows us to visualize the
effect of each predictor on the response, with a 95% credible interval.
If we had several predictors, the effect represented for one predictor
would be calculated by setting the other predictors to their mean
value.</p>
<pre class="r"><code>marginal_effects(bmod)</code></pre>
<pre><code>## Warning: Method &#39;marginal_effects&#39; is deprecated. Please use
## &#39;conditional_effects&#39; instead.</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>The <code>stanplot</code> function allows us to produce different
visualizations of the posterior distribution of the parameters. For
example, here we display the probability density
(<code>type = "dens"</code>) for the coefficient of
<code>log(Area)</code>:</p>
<pre class="r"><code>mcmc_plot(bmod, variable = &quot;b_logArea&quot;, type = &quot;dens&quot;)</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>The “bumpy” aspect of the density curve is due to the fact that the
posterior distribution is approximated by the algorithm, as we will see
in the next classes.</p>
</div>
<div id="checking-the-posterior-predictions" class="section level2">
<h2>Checking the posterior predictions</h2>
<p>Since Bayesian inference applies to many types of models, the
statistics used to test the fit vary from model to model. However, a
general strategy is to simulate datasets from the posterior distribution
of parameters and check whether the characteristics of the observed data
are well represented by these simulations. This technique is called the
<em>posterior predictive checks</em>.</p>
<p>In <em>brms</em>, several verification options are accessible from
the <code>pp_check</code> function, which saves us from having to code
the simulations and visualizations ourselves. For example, the
verification type “dens_overlay” superimposes the estimated probability
density of the set of observations (<span
class="math inline">\(y\)</span>, dark curve in the graph) on those
estimated from simulations of the fitted model (<span
class="math inline">\(y_{rep}\)</span>, light curves). The argument
<code>nsamples</code> determines the number of simulations
performed.</p>
<p>Each simulation generates a value for the parameters from their joint
posterior distribution, and then simulates the data from the model, so
the results include both the uncertainty in the parameters and the
random variation in the individual observations.</p>
<pre class="r"><code>pp_check(bmod, nsamples = 100, type = &quot;dens_overlay&quot;)</code></pre>
<pre><code>## Warning: Argument &#39;nsamples&#39; is deprecated. Please use argument &#39;ndraws&#39;
## instead.</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Here, the observation curve is not entirely contained within the
envelope created by the simulations, so there may be a fit problem.</p>
<p>This can also be seen with the “intervals” check, which compares each
observation (they are ordered on the <span
class="math inline">\(x\)</span> axis according to their position in the
dataset) with a prediction interval obtained by the model. In fact, each
light blue dot in the graph below indicates two intervals: the shorter
interval contains 50% of the posterior probability, while the longer
interval with a lighter line contains 95%.</p>
<pre class="r"><code>pp_check(bmod, nsamples = 100, type = &quot;intervals&quot;)</code></pre>
<pre><code>## Warning: Argument &#39;nsamples&#39; is deprecated. Please use argument &#39;ndraws&#39;
## instead.</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Since the majority of observations are outside their 95% prediction
interval, it seems that the observations are more variable than
expected. To verify this possibility in a more direct way, we can
calculate the standard deviation of the response for each posterior
simulation with the “stat” check type and the statistic “sd”.</p>
<pre class="r"><code>pp_check(bmod, nsamples = 100, type = &quot;stat&quot;, stat = &quot;sd&quot;)</code></pre>
<pre><code>## Warning: Argument &#39;nsamples&#39; is deprecated. Please use argument &#39;ndraws&#39;
## instead.</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="08E-Intro_Bayes_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Indeed, the observed standard deviation is extreme compared to the
model’s predictions, which supports the idea that the data are
overdispersed. A negative binomial distribution of the response may be
more appropriate here.</p>
<p>Note that the most useful summary statistics for model checking are
those that are not directly fitted by the model. For example, all
regression models are fit to properly represent the mean of the
observations. Since Poisson regression does not have a separate
parameter to fit the dispersion of the observations around their mean,
it is possible that the standard deviation is not well represented by
the model, making it a good statistic to check.</p>
</div>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<ul>
<li>In Bayesian inference, the posterior probability of a value of a
parameter is proportional to the product of its prior probability and
its likelihood according to the observed data.</li>
</ul>
<p><span class="math display">\[p(\theta | y) = \frac{p(y | \theta)
p(\theta)}{p(y)}\]</span></p>
<ul>
<li><p>For a complex model, the prior distribution is used to penalize
values of a parameter that are less plausible for the system under
study.</p></li>
<li><p>The influence of the prior distribution decreases as the number
of observations increases.</p></li>
<li><p>The credible intervals contain a certain % of the posterior
probability.</p></li>
<li><p>Model checking is done by comparing the data simulated by the
fitted model with the observations (posterior predictive
checks).</p></li>
<li><p>These checks must be based on summary statistics for which the
fit is not guaranteed by the model.</p></li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
